{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " model: PINN, layer: [2, 64, 64, 64, 64, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 15000/15000 [54:36<00:00,  4.58it/s, Loss=1.382e-02, loss_pde=2.107e-03, loss_bc=4.285e-05, loss_ic=1.167e-02, grouped_ic=1.13e-02,3.52e-04, lr=4.71e-05, D*=6.00e-02,3.69e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3276.73s\n",
      "[8.96655388e+01 8.96694884e+01 8.96876589e+01 ... 3.49071680e-02\n",
      " 3.44409981e-02 3.40513584e-02] False\n",
      "\n",
      " model: IA_PINN, layer: [2, 64, 64, 64, 64, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 15000/15000 [1:57:31<00:00,  2.13it/s, Loss=6.837e-03, loss_pde=4.482e-04, loss_bc=1.695e-05, loss_ic=6.372e-03, grouped_ic=6.21e-03,1.65e-04, lr=5.73e-05, D*=6.00e-02,2.83e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 7051.35s\n",
      "[9.00044830e+01 8.99948621e+01 8.99844768e+01 ... 5.41268988e-03\n",
      " 5.19665326e-03 5.02526034e-03] False\n",
      "\n",
      " model: PINN, layer: [2, 64, 64, 64, 64, 64, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 15000/15000 [1:19:14<00:00,  3.15it/s, Loss=1.331e-02, loss_pde=1.671e-03, loss_bc=2.672e-04, loss_ic=1.137e-02, grouped_ic=1.10e-02,3.40e-04, lr=4.71e-05, D*=6.00e-02,3.85e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4754.85s\n",
      "[8.97907573e+01 8.98212960e+01 8.99019277e+01 ... 8.49304707e-02\n",
      " 8.53512289e-02 8.59266036e-02] False\n",
      "\n",
      " model: IA_PINN, layer: [2, 64, 64, 64, 64, 64, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 15000/15000 [3:02:16<00:00,  1.37it/s, Loss=6.722e-03, loss_pde=5.415e-04, loss_bc=5.599e-06, loss_ic=6.175e-03, grouped_ic=5.98e-03,1.96e-04, lr=5.73e-05, D*=6.00e-02,2.92e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 10936.02s\n",
      "[8.99939938e+01 8.99952971e+01 8.99878510e+01 ... 4.49698914e-03\n",
      " 4.04103654e-03 3.63873646e-03] False\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "'''\n",
    "@Project ：Diffusion Reaction PDE\n",
    "@File    ：Diffusion_Reaction.py\n",
    "@IDE     ：VS Code\n",
    "@Author  ：Xuepeng Cheng\n",
    "@Date    ：2024年8月13日 \n",
    "'''\n",
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from DR_PINN import Diffusion_Reaction,Sampler\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \"\"\"Hard Code Part\"\"\"\n",
    "    L = 600 ##nm\n",
    "    h = 100 ##nm\n",
    "    geom = [0,L]\n",
    "\n",
    "    anneal_time= 60 ##min\n",
    "    TimeDomain = [0,anneal_time]\n",
    "        \n",
    "    D_A = 360  #6nm^2/s 360nm^2/min\n",
    "    k11,k12,k21 = 3.6e-3,3.6e-3,0\n",
    "\n",
    "    N_SA,N_SB,N_SC,N_SAB,N_SABB,N_SAAB = 90,48,90,90,90,90\n",
    "\n",
    "    lam_threshold = 1e6\n",
    "\n",
    "    sampler = Sampler(geom,TimeDomain,name='coordinates')\n",
    "    results = []\n",
    "\n",
    "    for depth in [4,5]:  ##[4,5,6,7,8]\n",
    "        for widths in [64]: ##[56,64,72]\n",
    "            layer = [2] + [widths]*depth + [6]\n",
    "            layer_str = f'{depth}x{widths}'\n",
    "            for mode in ['PINN','IA_PINN']:  # ['PINN','IA_PINN'] ['IAW_PINN','I_PINN]\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                model = Diffusion_Reaction(layer, sampler,\n",
    "                                D_A, k11, k12, k21,\n",
    "                                N_SA,N_SB,N_SC,N_SAB,N_SABB,N_SAAB,\n",
    "                                h,L,anneal_time,\n",
    "                                mode, lam_threshold)\n",
    "                model.train(nIter = 15000,num_interior = 100,num_boundary =2500, num_initial =10000,additional_points=0)              \n",
    "                \n",
    "                \"\"\"Validation Part\"\"\"\n",
    "                x = np.linspace(0,1,100)\n",
    "                t = np.linspace(0,1,100)\n",
    "                ms_x,ms_t = np.meshgrid(x,t)\n",
    "\n",
    "                x = np.ravel(ms_x).reshape(-1, 1)\n",
    "                t = np.ravel(ms_t).reshape(-1, 1)\n",
    "                pt_x = torch.from_numpy(x).float().requires_grad_(True).to(device)\n",
    "                pt_t = torch.from_numpy(t).float().requires_grad_(True).to(device)\n",
    "                X_star = torch.cat([pt_x,pt_t],1).to(device)\n",
    "\n",
    "                result = model.predict_u(X_star).data.cpu().numpy()\n",
    "                c_a,c_bc,c_c,c_ab,c_abb,c_aab = result[:,0],result[:,1],result[:,2],result[:,3],result[:,4],result[:,5]\n",
    "                c_a,c_bc,c_c,c_ab,c_abb,c_aab = [np.where((tensor < 0),np.array(0),tensor) for tensor in [c_a,c_bc,c_c,c_ab,c_abb,c_aab]]\n",
    "\n",
    "                data_dict_raw = {\n",
    "                    \"c_a\": c_a,\n",
    "                    \"c_bc\": c_bc,\n",
    "                    \"c_c\": c_c,\n",
    "                    \"c_ab\": c_ab,\n",
    "                    \"c_abb\": c_abb,\n",
    "                    \"c_aab\": c_aab\n",
    "                }\n",
    "\n",
    "                for name, concentration in data_dict_raw.items():\n",
    "                    # Convert the array to a DataFrame\n",
    "                    concentration = concentration.reshape(100, 100)\n",
    "\n",
    "                    df = pd.DataFrame(concentration)\n",
    "                    # print(df)\n",
    "                    df = df.transpose() \n",
    "\n",
    "                    new_df = pd.DataFrame(np.nan, index=range(101), columns=range(101))\n",
    "                    new_df.iloc[0, 1:] = np.linspace(0,60,100)\n",
    "                    new_df.iloc[1:,0] = np.linspace(0,600,100)\n",
    "\n",
    "                    new_df.iloc[1:, 1:] = df.values\n",
    "                    folder_path = f\"./Results/reaction t = 60/csv/RAW/{layer_str}_{mode}/\"\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    new_df.to_csv(os.path.join(folder_path, f\"{name}.csv\"), index=False, header=False)\n",
    "\n",
    "                c_a,c_bc,c_c,c_ab,c_abb,c_aab = c_a*N_SA, c_bc*N_SB, c_c*N_SC, c_ab*N_SAB, c_abb*N_SABB, c_aab*0\n",
    "                print(c_a,np.any(c_a < 0))\n",
    "                \n",
    "                c_a=c_a.reshape(100,100)\n",
    "                c_bc=c_bc.reshape(100,100)\n",
    "                c_c=c_c.reshape(100,100)\n",
    "                c_ab=c_ab.reshape(100,100)\n",
    "                c_abb=c_abb.reshape(100,100)\n",
    "                c_aab=c_aab.reshape(100,100)\n",
    "\n",
    "                data_dict = {\n",
    "                    \"c_a\": c_a,\n",
    "                    \"c_bc\": c_bc,\n",
    "                    \"c_c\": c_c,\n",
    "                    \"c_ab\": c_ab,\n",
    "                    \"c_abb\": c_abb,\n",
    "                    \"c_aab\": c_aab\n",
    "                }\n",
    "                for name, concentration in data_dict.items():\n",
    "                    df = pd.DataFrame(concentration)\n",
    "                    # print(df)\n",
    "                    df = df.transpose() \n",
    "\n",
    "                    new_df = pd.DataFrame(np.nan, index=range(101), columns=range(101))\n",
    "                    new_df.iloc[0, 1:] = np.linspace(0,60,100)\n",
    "                    new_df.iloc[1:,0] = np.linspace(0,600,100)\n",
    "\n",
    "                    new_df.iloc[1:, 1:] = df.values\n",
    "                    folder_path = f\"./Results/reaction t = 60/csv/Original/{layer_str}_{mode}/\"\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    new_df.to_csv(os.path.join(folder_path, f\"{name}.csv\"), index=False, header=False)\n",
    "\n",
    "                sum = c_a[99,:] + c_bc[99,:] + c_c[99,:] + c_ab[99,:] + c_abb[99,:] + c_aab[99,:]\n",
    "                \n",
    "                re_a = c_a[99,:] / sum * 100\n",
    "                re_bc = c_bc[99,:] / sum * 100 /2\n",
    "                re_c = c_c[99,:] / sum * 100\n",
    "                re_ab = c_ab[99,:] / sum * 100\n",
    "                re_abb = c_abb[99,:] / sum * 100\n",
    "                re_aab = c_aab[99,:] / sum * 100\n",
    "\n",
    "                loss_pde = model.loss_pde_log\n",
    "                loss_bc = model.loss_bc_log\n",
    "                loss_ic = model.loss_ic_log\n",
    "                loss_total = model.loss_total_log\n",
    "\n",
    "                component_x = np.linspace(0, 600, 100)\n",
    "\n",
    "                fig_1,ax = plt.subplots(1,2,figsize=(14,6))\n",
    "                ax[0].plot(component_x, re_a, label=r'Concentration of Ni', color=(97/255,108/255,140/255))\n",
    "                ax[0].plot(component_x, re_bc, label=r'Concentration of SiC', color=(86/140,140/255,135/255))\n",
    "                ax[0].plot(component_x, re_c, label=r'Concentration of C', color=(178/255,213/255,155/255))\n",
    "                ax[0].plot(component_x, re_ab, label=r'Concentration of NiSi', color=(242/255,222/255,121/255))\n",
    "                ax[0].plot(component_x, re_abb, label=r'Concentration of NiSi2', color=(217/255,95/255,24/255))\n",
    "                ax[0].set_title('Relative Concentration,time = 60')\n",
    "                ax[0].set_xlabel('x')\n",
    "                ax[0].set_ylabel('Concentration, %')\n",
    "                ax[0].set_xlim([0, 600])\n",
    "                ax[0].set_ylim([0, 110])\n",
    "                ax[0].legend()\n",
    "\n",
    "                ax[1].plot(loss_total, label='$\\mathcal{L}_{totall}$')\n",
    "                ax[1].plot(loss_pde, label='$\\mathcal{L}_{pde}$')\n",
    "                ax[1].plot(loss_bc, label='$\\mathcal{L}_{bc}$')\n",
    "                ax[1].plot(loss_ic, label='$\\mathcal{L}_{ic}$')\n",
    "                ax[1].set_yscale('log')\n",
    "                ax[1].set_xlabel('iterations')\n",
    "                ax[1].set_ylabel('Loss')\n",
    "                ax[1].legend()\n",
    "\n",
    "                save_path = f'./Results/reaction t = 60/'\n",
    "                file_name = f'{layer_str}_{mode}_loss.png'\n",
    "\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(save_path, file_name))\n",
    "                plt.close()\n",
    "\n",
    "                relative_u1 = model.log_relative_u1\n",
    "                relative_u2 = model.log_relative_u2\n",
    "                relative_u3 = model.log_relative_u3\n",
    "                relative_u4 = model.log_relative_u4\n",
    "                relative_u5 = model.log_relative_u5\n",
    "                fig_2,ax = plt.subplots(1,5,figsize=(22,4))\n",
    "                ax = ax.flatten()\n",
    "\n",
    "                def annotate_last_point(ax, data, label):\n",
    "                    x = len(data) - 1\n",
    "                    y = data[-1]\n",
    "                    ax.plot(x, y, 'ro',markersize = 2)  \n",
    "                    ax.annotate(f'{y:.2e}', xy=(x, y), xytext=(x, y*1.1))\n",
    "                    \n",
    "                ax[0].plot(relative_u1)\n",
    "                ax[0].set_title('Relative Error of Ni')\n",
    "                ax[0].set_yscale('log')\n",
    "                annotate_last_point(ax[0], relative_u1, 'Ni')\n",
    "\n",
    "                ax[1].plot(relative_u2)\n",
    "                ax[1].set_title('Relative Error of SiC')\n",
    "                ax[1].set_yscale('log')\n",
    "                annotate_last_point(ax[1], relative_u2, 'SiC')\n",
    "\n",
    "                ax[2].plot(relative_u3)\n",
    "                ax[2].set_title('Relative Error of C')\n",
    "                ax[2].set_yscale('log')\n",
    "                annotate_last_point(ax[2], relative_u3, 'C')\n",
    "\n",
    "                ax[3].plot(relative_u4)\n",
    "                ax[3].set_title('Relative Error of NiSi')\n",
    "                ax[3].set_yscale('log')\n",
    "                annotate_last_point(ax[3], relative_u4, 'NiSi')\n",
    "\n",
    "                ax[4].plot(relative_u5)\n",
    "                ax[4].set_title('Relative Error of $NiSi_2$')\n",
    "                ax[4].set_yscale('log')\n",
    "                annotate_last_point(ax[4], relative_u5, '$NiSi2$')\n",
    "\n",
    "                save_path = f'./Results/reaction t = 60/'\n",
    "                file_name = f'{layer_str}_{mode}_relative_Error.png'\n",
    "\n",
    "                if not os.path.exists(save_path):                                       \n",
    "                    os.makedirs(save_path)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(save_path, file_name))\n",
    "                plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
