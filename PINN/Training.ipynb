{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " model: PINN, layer: [2, 64, 64, 64, 64, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 10000/10000 [16:38<00:00, 10.01it/s, Loss=1.659e-02, loss_pde=2.216e-03, loss_bc=1.976e-04, loss_ic=1.418e-02, grouped_ic=1.39e-02,3.18e-04, lr=1.35e-04, D*=6.00e-02,3.53e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 998.78s\n",
      "[8.9677467e+01 8.9705505e+01 8.9785095e+01 ... 5.4679744e-02 5.3872466e-02\n",
      " 5.3220652e-02] False\n",
      "\n",
      " model: IA_PINN, layer: [2, 64, 64, 64, 64, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 10000/10000 [33:53<00:00,  4.92it/s, Loss=8.590e-03, loss_pde=7.969e-04, loss_bc=6.750e-05, loss_ic=7.726e-03, grouped_ic=7.50e-03,2.24e-04, lr=5.73e-05, D*=6.00e-02,3.41e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2033.72s\n",
      "[9.0303604e+01 9.0256516e+01 9.0167046e+01 ... 4.7693978e-04 3.6892915e-04\n",
      " 2.8476366e-04] False\n",
      "\n",
      " model: PINN, layer: [2, 64, 64, 64, 64, 64, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████▌                                                      | 929/10000 [01:43<16:48,  9.00it/s, Loss=6.481e-02, loss_pde=1.020e-02, loss_bc=1.242e-02, loss_ic=4.219e-02, grouped_ic=4.01e-02,2.13e-03, lr=9.00e-04, D*=5.99e-02,9.53e-03]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 53\u001b[0m\n\u001b[0;32m     46\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m     48\u001b[0m model \u001b[38;5;241m=\u001b[39m Diffusion_Reaction(layer, sampler,\n\u001b[0;32m     49\u001b[0m                 D_A, k11, k12, k21,\n\u001b[0;32m     50\u001b[0m                 N_SA,N_SB,N_SC,N_SAB,N_SABB,N_SAAB,\n\u001b[0;32m     51\u001b[0m                 h,L,anneal_time,\n\u001b[0;32m     52\u001b[0m                 mode, lam_threshold)\n\u001b[1;32m---> 53\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnIter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_interior\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_boundary\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_initial\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43madditional_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m              \n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validation Part\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32me:\\Report 10\\PINN\\DR_PINN.py:363\u001b[0m, in \u001b[0;36mDiffusion_Reaction.train\u001b[1;34m(self, nIter, num_interior, num_boundary, num_initial, additional_points)\u001b[0m\n\u001b[0;32m    360\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, norm_type\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)  \n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss                \n\u001b[1;32m--> 363\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosuer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m error_u1,error_u2,error_u3,error_u4,error_u5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_error()\n\u001b[0;32m    366\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''relative Error'''\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:148\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 148\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    151\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32me:\\Report 10\\PINN\\DR_PINN.py:357\u001b[0m, in \u001b[0;36mDiffusion_Reaction.train.<locals>.closuer\u001b[1;34m()\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIAW_PINN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI_PINN\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    355\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAW_loss_function(loss_pde,loss_bc,loss_ic_gr1,loss_ic_gr2)\n\u001b[1;32m--> 357\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m##Add gradient clipping, which is really heapful\u001b[39;00m\n\u001b[0;32m    360\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, norm_type\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)  \n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "'''\n",
    "@Project ：Diffusion Reaction PDE\n",
    "@File    ：Diffusion_Reaction.py\n",
    "@IDE     ：VS Code\n",
    "@Author  ：Xuepeng Cheng\n",
    "@Date    ：2024年8月13日 \n",
    "'''\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from DR_PINN import Diffusion_Reaction,Sampler\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \"\"\"Hard Code Part\"\"\"\n",
    "    L = 600 ##nm\n",
    "    h = 100 ##nm\n",
    "    geom = [0,L]\n",
    "\n",
    "    anneal_time= 60 ##min\n",
    "    TimeDomain = [0,anneal_time]\n",
    "        \n",
    "    D_A = 360  #6nm^2/s 360nm^2/min\n",
    "    k11,k12,k21 = 3.6e-3,3.6e-3,0\n",
    "\n",
    "    N_SA,N_SB,N_SC,N_SAB,N_SABB,N_SAAB = 90,48,90,90,90,90\n",
    "\n",
    "    lam_threshold = 1e6\n",
    "\n",
    "    sampler = Sampler(geom,TimeDomain,name='coordinates')\n",
    "    results = []\n",
    "\n",
    "    for depth in [4,5]:  ##[4,5,6,7,8]\n",
    "        for widths in [64]: ##[56,64,72]\n",
    "            layer = [2] + [widths]*depth + [6]\n",
    "            layer_str = f'{depth}x{widths}'\n",
    "            for mode in ['PINN','IA_PINN']:  # ['PINN','IA_PINN'] ['IAW_PINN','I_PINN]\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                model = Diffusion_Reaction(layer, sampler,\n",
    "                                D_A, k11, k12, k21,\n",
    "                                N_SA,N_SB,N_SC,N_SAB,N_SABB,N_SAAB,\n",
    "                                h,L,anneal_time,\n",
    "                                mode, lam_threshold)\n",
    "                model.train(nIter = 15000,num_interior = 100,num_boundary =2500, num_initial =10000,additional_points=0)              \n",
    "                \n",
    "                \"\"\"Validation Part\"\"\"\n",
    "                x = np.linspace(0,1,100)\n",
    "                t = np.linspace(0,1,100)\n",
    "                ms_x,ms_t = np.meshgrid(x,t)\n",
    "\n",
    "                x = np.ravel(ms_x).reshape(-1, 1)\n",
    "                t = np.ravel(ms_t).reshape(-1, 1)\n",
    "                pt_x = torch.from_numpy(x).float().requires_grad_(True).to(device)\n",
    "                pt_t = torch.from_numpy(t).float().requires_grad_(True).to(device)\n",
    "                X_star = torch.cat([pt_x,pt_t],1).to(device)\n",
    "\n",
    "                result = model.predict_u(X_star).data.cpu().numpy()\n",
    "                c_a,c_bc,c_c,c_ab,c_abb,c_aab = result[:,0],result[:,1],result[:,2],result[:,3],result[:,4],result[:,5]\n",
    "                c_a,c_bc,c_c,c_ab,c_abb,c_aab = [np.where((tensor < 0),np.array(0),tensor) for tensor in [c_a,c_bc,c_c,c_ab,c_abb,c_aab]]\n",
    "\n",
    "                data_dict_raw = {\n",
    "                    \"c_a\": c_a,\n",
    "                    \"c_bc\": c_bc,\n",
    "                    \"c_c\": c_c,\n",
    "                    \"c_ab\": c_ab,\n",
    "                    \"c_abb\": c_abb,\n",
    "                    \"c_aab\": c_aab\n",
    "                }\n",
    "\n",
    "                for name, concentration in data_dict_raw.items():\n",
    "                    # Convert the array to a DataFrame\n",
    "                    concentration = concentration.reshape(100, 100)\n",
    "\n",
    "                    df = pd.DataFrame(concentration)\n",
    "                    # print(df)\n",
    "                    df = df.transpose() \n",
    "\n",
    "                    new_df = pd.DataFrame(np.nan, index=range(101), columns=range(101))\n",
    "                    new_df.iloc[0, 1:] = np.linspace(0,60,100)\n",
    "                    new_df.iloc[1:,0] = np.linspace(0,600,100)\n",
    "\n",
    "                    new_df.iloc[1:, 1:] = df.values\n",
    "                    folder_path = f\"./Results/reaction t = 60/csv/RAW/{layer_str}_{mode}/\"\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    new_df.to_csv(os.path.join(folder_path, f\"{name}.csv\"), index=False, header=False)\n",
    "\n",
    "                c_a,c_bc,c_c,c_ab,c_abb,c_aab = c_a*N_SA, c_bc*N_SB, c_c*N_SC, c_ab*N_SAB, c_abb*N_SABB, c_aab*0\n",
    "                print(c_a,np.any(c_a < 0))\n",
    "                \n",
    "                c_a=c_a.reshape(100,100)\n",
    "                c_bc=c_bc.reshape(100,100)\n",
    "                c_c=c_c.reshape(100,100)\n",
    "                c_ab=c_ab.reshape(100,100)\n",
    "                c_abb=c_abb.reshape(100,100)\n",
    "                c_aab=c_aab.reshape(100,100)\n",
    "\n",
    "                data_dict = {\n",
    "                    \"c_a\": c_a,\n",
    "                    \"c_bc\": c_bc,\n",
    "                    \"c_c\": c_c,\n",
    "                    \"c_ab\": c_ab,\n",
    "                    \"c_abb\": c_abb,\n",
    "                    \"c_aab\": c_aab\n",
    "                }\n",
    "                for name, concentration in data_dict.items():\n",
    "                    df = pd.DataFrame(concentration)\n",
    "                    # print(df)\n",
    "                    df = df.transpose() \n",
    "\n",
    "                    new_df = pd.DataFrame(np.nan, index=range(101), columns=range(101))\n",
    "                    new_df.iloc[0, 1:] = np.linspace(0,60,100)\n",
    "                    new_df.iloc[1:,0] = np.linspace(0,600,100)\n",
    "\n",
    "                    new_df.iloc[1:, 1:] = df.values\n",
    "                    folder_path = f\"./Results/reaction t = 60/csv/Original/{layer_str}_{mode}/\"\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    new_df.to_csv(os.path.join(folder_path, f\"{name}.csv\"), index=False, header=False)\n",
    "\n",
    "                sum = c_a[99,:] + c_bc[99,:] + c_c[99,:] + c_ab[99,:] + c_abb[99,:] + c_aab[99,:]\n",
    "                \n",
    "                re_a = c_a[99,:] / sum * 100\n",
    "                re_bc = c_bc[99,:] / sum * 100 /2\n",
    "                re_c = c_c[99,:] / sum * 100\n",
    "                re_ab = c_ab[99,:] / sum * 100\n",
    "                re_abb = c_abb[99,:] / sum * 100\n",
    "                re_aab = c_aab[99,:] / sum * 100\n",
    "\n",
    "                loss_pde = model.loss_pde_log\n",
    "                loss_bc = model.loss_bc_log\n",
    "                loss_ic = model.loss_ic_log\n",
    "                loss_total = model.loss_total_log\n",
    "\n",
    "                component_x = np.linspace(0, 600, 100)\n",
    "\n",
    "                fig_1,ax = plt.subplots(1,2,figsize=(14,6))\n",
    "                ax[0].plot(component_x, re_a, label=r'Concentration of Ni', color=(97/255,108/255,140/255))\n",
    "                ax[0].plot(component_x, re_bc, label=r'Concentration of SiC', color=(86/140,140/255,135/255))\n",
    "                ax[0].plot(component_x, re_c, label=r'Concentration of C', color=(178/255,213/255,155/255))\n",
    "                ax[0].plot(component_x, re_ab, label=r'Concentration of NiSi', color=(242/255,222/255,121/255))\n",
    "                ax[0].plot(component_x, re_abb, label=r'Concentration of NiSi2', color=(217/255,95/255,24/255))\n",
    "                ax[0].set_title('Relative Concentration,time = 60')\n",
    "                ax[0].set_xlabel('x')\n",
    "                ax[0].set_ylabel('Concentration, %')\n",
    "                ax[0].set_xlim([0, 600])\n",
    "                ax[0].set_ylim([0, 110])\n",
    "                ax[0].legend()\n",
    "\n",
    "                ax[1].plot(loss_total, label='$\\mathcal{L}_{totall}$')\n",
    "                ax[1].plot(loss_pde, label='$\\mathcal{L}_{pde}$')\n",
    "                ax[1].plot(loss_bc, label='$\\mathcal{L}_{bc}$')\n",
    "                ax[1].plot(loss_ic, label='$\\mathcal{L}_{ic}$')\n",
    "                ax[1].set_yscale('log')\n",
    "                ax[1].set_xlabel('iterations')\n",
    "                ax[1].set_ylabel('Loss')\n",
    "                ax[1].legend()\n",
    "\n",
    "                save_path = f'./Results/reaction t = 60/'\n",
    "                file_name = f'{layer_str}_{mode}_loss.png'\n",
    "\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(save_path, file_name))\n",
    "                plt.close()\n",
    "\n",
    "                relative_u1 = model.log_relative_u1\n",
    "                relative_u2 = model.log_relative_u2\n",
    "                relative_u3 = model.log_relative_u3\n",
    "                relative_u4 = model.log_relative_u4\n",
    "                relative_u5 = model.log_relative_u5\n",
    "                fig_2,ax = plt.subplots(1,5,figsize=(22,4))\n",
    "                ax = ax.flatten()\n",
    "\n",
    "                def annotate_last_point(ax, data, label):\n",
    "                    x = len(data) - 1\n",
    "                    y = data[-1]\n",
    "                    ax.plot(x, y, 'ro',markersize = 2)  \n",
    "                    ax.annotate(f'{y:.2e}', xy=(x, y), xytext=(x, y*1.1))\n",
    "                    \n",
    "                ax[0].plot(relative_u1)\n",
    "                ax[0].set_title('Relative Error of Ni')\n",
    "                ax[0].set_yscale('log')\n",
    "                annotate_last_point(ax[0], relative_u1, 'Ni')\n",
    "\n",
    "                ax[1].plot(relative_u2)\n",
    "                ax[1].set_title('Relative Error of SiC')\n",
    "                ax[1].set_yscale('log')\n",
    "                annotate_last_point(ax[1], relative_u2, 'SiC')\n",
    "\n",
    "                ax[2].plot(relative_u3)\n",
    "                ax[2].set_title('Relative Error of C')\n",
    "                ax[2].set_yscale('log')\n",
    "                annotate_last_point(ax[2], relative_u3, 'C')\n",
    "\n",
    "                ax[3].plot(relative_u4)\n",
    "                ax[3].set_title('Relative Error of NiSi')\n",
    "                ax[3].set_yscale('log')\n",
    "                annotate_last_point(ax[3], relative_u4, 'NiSi')\n",
    "\n",
    "                ax[4].plot(relative_u5)\n",
    "                ax[4].set_title('Relative Error of $NiSi_2$')\n",
    "                ax[4].set_yscale('log')\n",
    "                annotate_last_point(ax[4], relative_u5, '$NiSi2$')\n",
    "\n",
    "                save_path = f'./Results/reaction t = 60/'\n",
    "                file_name = f'{layer_str}_{mode}_relative_Error.png'\n",
    "\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(save_path, file_name))\n",
    "                plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
