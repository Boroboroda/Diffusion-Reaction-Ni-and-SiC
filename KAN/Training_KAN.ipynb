{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda:0\n",
      "\n",
      " model: ChebyKAN, layer: [2, 20, 20, 20, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                                             | 95/6000 [00:29<30:27,  3.23it/s, Loss=3.008e-01, loss_pde=8.814e-02, loss_bc=1.408e-02, loss_ic=1.986e-01, grouped_ic=1.97e-01,1.32e-03, lr=1.00e-02, D*=5.98e-02,7.55e-03]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 55\u001b[0m\n\u001b[0;32m     48\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m Diffusion_Reaction(layer, sampler,\n\u001b[0;32m     51\u001b[0m                 D_A, k11, k12, k21,\n\u001b[0;32m     52\u001b[0m                 N_SA,N_SB,N_SC,N_SAB,N_SABB,N_SAAB,\n\u001b[0;32m     53\u001b[0m                 h,L,anneal_time,\n\u001b[0;32m     54\u001b[0m                 mode, lam_threshold)\n\u001b[1;32m---> 55\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnIter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_interior\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_boundary\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_initial\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43madditional_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m              \n\u001b[0;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validation Part\"\"\"\u001b[39;00m\n\u001b[0;32m     58\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32me:\\Report 10\\KAN\\DR_KAN.py:392\u001b[0m, in \u001b[0;36mDiffusion_Reaction.train\u001b[1;34m(self, nIter, num_interior, num_boundary, num_initial, additional_points)\u001b[0m\n\u001b[0;32m    389\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, norm_type\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)  \n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss                \n\u001b[1;32m--> 392\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosuer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m error_u1,error_u2,error_u3,error_u4,error_u5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_error()\n\u001b[0;32m    395\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''relative Error'''\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:148\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 148\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    151\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32me:\\Report 10\\KAN\\DR_KAN.py:362\u001b[0m, in \u001b[0;36mDiffusion_Reaction.train.<locals>.closuer\u001b[1;34m()\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIAW_KAN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI_KAN\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_ic\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 362\u001b[0m loss_pde,loss_bc,loss_ic,D_star,loss_ic_gr1,loss_ic_gr2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_interior\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_boundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43madditional_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKAN\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChebyKAN\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    366\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(loss_pde,loss_bc,loss_ic)\n",
      "File \u001b[1;32me:\\Report 10\\KAN\\DR_KAN.py:285\u001b[0m, in \u001b[0;36mDiffusion_Reaction.epoch_train\u001b[1;34m(self, num_interior, num_boundary, num_initial, additional_points)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mepoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m,num_interior,num_boundary, num_initial,additional_points):\n\u001b[0;32m    284\u001b[0m     coords_pde,coords_bc,coords_ic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_sample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler, num_interior,num_boundary, num_initial,additional_points)\n\u001b[1;32m--> 285\u001b[0m     loss_pde,loss_bc,loss_ic,D_star,loss_ic_gr1,loss_ic_gr2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion_reaction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords_pde\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcoords_bc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcoords_ic\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_pde,loss_bc,loss_ic,D_star,loss_ic_gr1,loss_ic_gr2\n",
      "File \u001b[1;32me:\\Report 10\\KAN\\DR_KAN.py:254\u001b[0m, in \u001b[0;36mDiffusion_Reaction.diffusion_reaction\u001b[1;34m(self, coords_pde, coords_bc, coords_ic)\u001b[0m\n\u001b[0;32m    252\u001b[0m ca_in_h,cbc_in_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn(tensor_h)[:,\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn(tensor_h)[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    253\u001b[0m ca_in_L,cbc_in_L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn(tensor_L)[:,\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn(tensor_L)[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 254\u001b[0m cc_init,cab_init,cabb_init,caab_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords_ic\u001b[49m\u001b[43m)\u001b[49m[:,\u001b[38;5;241m2\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn(coords_ic)[:,\u001b[38;5;241m3\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn(coords_ic)[:,\u001b[38;5;241m4\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdnn(coords_ic)[:,\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m    256\u001b[0m loss_ic_group1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((ca_in_h \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_SA\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_SA)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((cbc_in_L \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_SB\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_SB)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(ca_in_L\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(cbc_in_h\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    257\u001b[0m loss_ic_group2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(cc_init \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(cab_init \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(cabb_init \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(caab_init \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Report 10\\KAN\\KANs\\Cheby_KAN.py:243\u001b[0m, in \u001b[0;36mChebyKAN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m实现模型的前向传播。\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m    torch.Tensor: 输出张量，形状为 (..., out_features)。\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m--> 243\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# 对除最后一层外的所有层应用LayerNorm\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_layer_norm \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Report 10\\KAN\\KANs\\Cheby_KAN.py:149\u001b[0m, in \u001b[0;36mChebyKANLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    144\u001b[0m T_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchebyshev_polynomials(x)  \u001b[38;5;66;03m# 形状为 (batch_size, in_features, degree + 1)\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# 计算 Chebyshev 部分的输出\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# 将 cheby_coeffs 转换为形状 (out_features, in_features, degree + 1)\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# 使用 einsum 进行高效的张量乘法\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m cheby_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbik,oik->bo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheby_coeffs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# 合并基础输出和 Chebyshev 输出\u001b[39;00m\n\u001b[0;32m    152\u001b[0m output \u001b[38;5;241m=\u001b[39m base_output \u001b[38;5;241m+\u001b[39m cheby_output\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\functional.py:385\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    387\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "@Project ：Diffusion Reaction PDE\n",
    "@File    ：Diffusion_Reaction.py\n",
    "@IDE     ：VS Code\n",
    "@Author  ：Xuepeng Cheng\n",
    "@Date    ：2024年8月13日 \n",
    "'''\n",
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from DR_KAN import Diffusion_Reaction,Sampler\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \"\"\"Hard Code Part\"\"\"\n",
    "    L = 600 ##nm\n",
    "    h = 100 ##nm\n",
    "    geom = [0,L]\n",
    "\n",
    "    anneal_time= 60 ##min\n",
    "    TimeDomain = [0,anneal_time]\n",
    "        \n",
    "    D_A = 360  #6nm^2/s 360nm^2/min\n",
    "    k11,k12,k21 = 3.6e-3,3.6e-3,0\n",
    "\n",
    "    N_SA,N_SB,N_SC,N_SAB,N_SABB,N_SAAB = 90,48,90,90,90,90\n",
    "\n",
    "    lam_threshold = 1e6\n",
    "\n",
    "    sampler = Sampler(geom,TimeDomain,name='coordinates')\n",
    "    results = []\n",
    "\n",
    "    for depth in [3]:  ##[4,5,6,7,8]\n",
    "        for widths in [20]: ##[56,64,72]\n",
    "            layer = [2] + [widths]*depth + [6]\n",
    "            layer_str = f'{depth}x{widths}'\n",
    "            for mode in ['ChebyKAN','KAN']:  # ['PINN','IA_PINN'] ['IAW_PINN','I_PINN]\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                model = Diffusion_Reaction(layer, sampler,\n",
    "                                D_A, k11, k12, k21,\n",
    "                                N_SA,N_SB,N_SC,N_SAB,N_SABB,N_SAAB,\n",
    "                                h,L,anneal_time,\n",
    "                                mode, lam_threshold)\n",
    "                model.train(nIter = 6000,num_interior = 100,num_boundary =2500, num_initial =10000,additional_points=0)              \n",
    "                \n",
    "                \"\"\"Validation Part\"\"\"\n",
    "                x = np.linspace(0,1,100)\n",
    "                t = np.linspace(0,1,100)\n",
    "                ms_x,ms_t = np.meshgrid(x,t)\n",
    "\n",
    "                x = np.ravel(ms_x).reshape(-1, 1)\n",
    "                t = np.ravel(ms_t).reshape(-1, 1)\n",
    "                pt_x = torch.from_numpy(x).float().requires_grad_(True).to(device)\n",
    "                pt_t = torch.from_numpy(t).float().requires_grad_(True).to(device)\n",
    "                X_star = torch.cat([pt_x,pt_t],1).to(device)\n",
    "\n",
    "                result = model.predict_u(X_star).data.cpu().numpy()\n",
    "                c_a,c_bc,c_c,c_ab,c_abb,c_aab = result[:,0],result[:,1],result[:,2],result[:,3],result[:,4],result[:,5]\n",
    "                c_a,c_bc,c_c,c_ab,c_abb,c_aab = [np.where((tensor < 0),np.array(0),tensor) for tensor in [c_a,c_bc,c_c,c_ab,c_abb,c_aab]]\n",
    "\n",
    "                data_dict_raw = {\n",
    "                    \"c_a\": c_a,\n",
    "                    \"c_bc\": c_bc,\n",
    "                    \"c_c\": c_c,\n",
    "                    \"c_ab\": c_ab,\n",
    "                    \"c_abb\": c_abb,\n",
    "                    \"c_aab\": c_aab\n",
    "                }\n",
    "\n",
    "                for name, concentration in data_dict_raw.items():\n",
    "                    # Convert the array to a DataFrame\n",
    "                    concentration = concentration.reshape(100, 100)\n",
    "\n",
    "                    df = pd.DataFrame(concentration)\n",
    "                    # print(df)\n",
    "                    df = df.transpose() \n",
    "\n",
    "                    new_df = pd.DataFrame(np.nan, index=range(101), columns=range(101))\n",
    "                    new_df.iloc[0, 1:] = np.linspace(0,60,100)\n",
    "                    new_df.iloc[1:,0] = np.linspace(0,600,100)\n",
    "\n",
    "                    new_df.iloc[1:, 1:] = df.values\n",
    "                    folder_path = f\"./Results/reaction t = 60/csv/RAW/{layer_str}_{mode}/\"\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    new_df.to_csv(os.path.join(folder_path, f\"{name}.csv\"), index=False, header=False)\n",
    "\n",
    "                c_a,c_bc,c_c,c_ab,c_abb,c_aab = c_a*N_SA, c_bc*N_SB, c_c*N_SC, c_ab*N_SAB, c_abb*N_SABB, c_aab*0\n",
    "                \n",
    "                c_a=c_a.reshape(100,100)\n",
    "                c_bc=c_bc.reshape(100,100)\n",
    "                c_c=c_c.reshape(100,100)\n",
    "                c_ab=c_ab.reshape(100,100)\n",
    "                c_abb=c_abb.reshape(100,100)\n",
    "                c_aab=c_aab.reshape(100,100)\n",
    "\n",
    "                data_dict = {\n",
    "                    \"c_a\": c_a,\n",
    "                    \"c_bc\": c_bc,\n",
    "                    \"c_c\": c_c,\n",
    "                    \"c_ab\": c_ab,\n",
    "                    \"c_abb\": c_abb,\n",
    "                    \"c_aab\": c_aab\n",
    "                }\n",
    "                for name, concentration in data_dict.items():\n",
    "                    df = pd.DataFrame(concentration)\n",
    "                    # print(df)\n",
    "                    df = df.transpose() \n",
    "\n",
    "                    new_df = pd.DataFrame(np.nan, index=range(101), columns=range(101))\n",
    "                    new_df.iloc[0, 1:] = np.linspace(0,60,100)\n",
    "                    new_df.iloc[1:,0] = np.linspace(0,600,100)\n",
    "\n",
    "                    new_df.iloc[1:, 1:] = df.values\n",
    "                    folder_path = f\"./Results/reaction t = 60/csv/Original/{layer_str}_{mode}/\"\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    new_df.to_csv(os.path.join(folder_path, f\"{name}.csv\"), index=False, header=False)\n",
    "\n",
    "                sum = c_a[99,:] + c_bc[99,:] + c_c[99,:] + c_ab[99,:] + c_abb[99,:] + c_aab[99,:]\n",
    "                \n",
    "                re_a = c_a[99,:] / sum * 100\n",
    "                re_bc = c_bc[99,:] / sum * 100 /2\n",
    "                re_c = c_c[99,:] / sum * 100\n",
    "                re_ab = c_ab[99,:] / sum * 100\n",
    "                re_abb = c_abb[99,:] / sum * 100\n",
    "                re_aab = c_aab[99,:] / sum * 100\n",
    "\n",
    "                loss_pde = model.loss_pde_log\n",
    "                loss_bc = model.loss_bc_log\n",
    "                loss_ic = model.loss_ic_log\n",
    "                loss_total = model.loss_total_log\n",
    "\n",
    "                component_x = np.linspace(0, 600, 100)\n",
    "\n",
    "                fig_1,ax = plt.subplots(1,2,figsize=(14,6))\n",
    "                ax[0].plot(component_x, re_a, label=r'Concentration of Ni', color=(97/255,108/255,140/255))\n",
    "                ax[0].plot(component_x, re_bc, label=r'Concentration of SiC', color=(86/140,140/255,135/255))\n",
    "                ax[0].plot(component_x, re_c, label=r'Concentration of C', color=(178/255,213/255,155/255))\n",
    "                ax[0].plot(component_x, re_ab, label=r'Concentration of NiSi', color=(242/255,222/255,121/255))\n",
    "                ax[0].plot(component_x, re_abb, label=r'Concentration of NiSi2', color=(217/255,95/255,24/255))\n",
    "                ax[0].set_title('Relative Concentration,time = 60')\n",
    "                ax[0].set_xlabel('x')\n",
    "                ax[0].set_ylabel('Concentration, %')\n",
    "                ax[0].set_xlim([0, 600])\n",
    "                ax[0].set_ylim([0, 110])\n",
    "                ax[0].legend()\n",
    "\n",
    "                ax[1].plot(loss_total, label='$\\mathcal{L}_{totall}$')\n",
    "                ax[1].plot(loss_pde, label='$\\mathcal{L}_{pde}$')\n",
    "                ax[1].plot(loss_bc, label='$\\mathcal{L}_{bc}$')\n",
    "                ax[1].plot(loss_ic, label='$\\mathcal{L}_{ic}$')\n",
    "                ax[1].set_yscale('log')\n",
    "                ax[1].set_xlabel('iterations')\n",
    "                ax[1].set_ylabel('Loss')\n",
    "                ax[1].legend()\n",
    "\n",
    "                save_path = f'./Results/reaction t = 60/'\n",
    "                file_name = f'{layer_str}_{mode}_loss.png'\n",
    "\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(save_path, file_name))\n",
    "                plt.close()\n",
    "\n",
    "                relative_u1 = model.log_relative_u1\n",
    "                relative_u2 = model.log_relative_u2\n",
    "                relative_u3 = model.log_relative_u3\n",
    "                relative_u4 = model.log_relative_u4\n",
    "                relative_u5 = model.log_relative_u5\n",
    "                fig_2,ax = plt.subplots(1,5,figsize=(22,4))\n",
    "                ax = ax.flatten()\n",
    "\n",
    "                def annotate_last_point(ax, data, label):\n",
    "                    x = len(data) - 1\n",
    "                    y = data[-1]\n",
    "                    ax.plot(x, y, 'ro',markersize = 2)  \n",
    "                    ax.annotate(f'{y:.2e}', xy=(x, y), xytext=(x, y*1.1))\n",
    "                    \n",
    "                ax[0].plot(relative_u1)\n",
    "                ax[0].set_title('Relative Error of Ni')\n",
    "                ax[0].set_yscale('log')\n",
    "                annotate_last_point(ax[0], relative_u1, 'Ni')\n",
    "\n",
    "                ax[1].plot(relative_u2)\n",
    "                ax[1].set_title('Relative Error of SiC')\n",
    "                ax[1].set_yscale('log')\n",
    "                annotate_last_point(ax[1], relative_u2, 'SiC')\n",
    "\n",
    "                ax[2].plot(relative_u3)\n",
    "                ax[2].set_title('Relative Error of C')\n",
    "                ax[2].set_yscale('log')\n",
    "                annotate_last_point(ax[2], relative_u3, 'C')\n",
    "\n",
    "                ax[3].plot(relative_u4)\n",
    "                ax[3].set_title('Relative Error of NiSi')\n",
    "                ax[3].set_yscale('log')\n",
    "                annotate_last_point(ax[3], relative_u4, 'NiSi')\n",
    "\n",
    "                ax[4].plot(relative_u5)\n",
    "                ax[4].set_title('Relative Error of $NiSi_2$')\n",
    "                ax[4].set_yscale('log')\n",
    "                annotate_last_point(ax[4], relative_u5, '$NiSi2$')\n",
    "\n",
    "                save_path = f'./Results/reaction t = 60/'\n",
    "                file_name = f'{layer_str}_{mode}_relative_Error.png'\n",
    "\n",
    "                if not os.path.exists(save_path):                                       \n",
    "                    os.makedirs(save_path)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(save_path, file_name))\n",
    "                plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
